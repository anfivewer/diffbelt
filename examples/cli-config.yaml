collections:
  - name: log-lines
    manual: no
    format: utf8

  - name: parsed-log-lines
    format: json

  - name: parsed-log-lines:1d
    format: json

  - name: kicks
  - name: kicks:1h
  - name: kicks:1d

  - name: updateMs:1d:p
    format: json

  - name: uniqueChats:1d
    format: json

  - name: uniqueUsers:1d

functions:
  parsed_log_lines_day_date_as_key: &parsed_log_lines_day_date_as_key
    - vars:
        date:
          date_from_unix_ms: source.timestampMilliseconds
        key: ${date.year}-${(padLeft date.month '0' 2)}-${(padLeft date.day '0', 2)}
    - return: key
  parsed_log_lines_aggregate_increment_log_keys: &parsed_log_lines_aggregate_increment_log_keys
    - vars:
        count: accumulator.log_keys.get_or_default(key, 0)
    - update_map:
        var: accumulator.log_keys
        key: key
        value: count + value
  take_str_before_space: &take_str_before_space
    - regexp:
        var: str
        regexp: ^([^\s]+)\s
        groups:
          - str
    - return: str
  update_ms_percentiles_increment_ms_by_type: &update_ms_percentiles_increment_ms_by_type
    - vars:
        count: accumulator.ms_by_type.get_or_default(key, 0)
    - update_map:
        var: accumulator.ms_by_type
        key: key
        value: count + value

transforms:
  - name: parse_lines
    from: log-lines
    to: parsed-log-lines
    reader_name: log-lines
    map_filter:
      - if:
          condition: (is_none map_filter_new_value)
          then:
            - return:
                key: map_filter_key
                value: (none)
      - regexp:
          var: map_filter_key
          parts:
            log_level: '''(T|I|W|E|S)'''
            timestamp: '''(\d{4}-\d\d-\d\dT\d\d:\d\d:\d\d\.\d{1,3}Z)\.(\d{1,3})'''
            start: '"^(?:${log_level} ${timestamp}|${timestamp} ${log_level})"'
            end: '''((?:\\ |[^\s])+) ((?:\\ |[^\s])+)(.*)$'''
          regexp: '"${start} ${end}"'
          groups:
            - log_level_a
            - date_a
            - microseconds_a
            - date_b
            - microseconds_b
            - log_level_b
            - logger_key_escaped
            - log_key_escaped
            - rest
      - vars:
          log_level:
            non_empty_string: [log_level_a, log_level_b]
          date:
            non_empty_string: [date_a, date_b]
          microseconds_str:
            non_empty_string: [microseconds_a, microseconds_b]
          timestamp_ms:
            parse_date_to_ms: date
          microseconds:
            parse_uint: microseconds_str
          timestamp_string: '"${date}.${microseconds_str}"'
          logger_key:
            regexp_replace:
              var: logger_key_escaped
              from: \\(\\|\s)
              to: $1
          log_key:
            regexp_replace:
              var: log_key_escaped
              from: \\(\\|\s)
              to: $1
          props: (map)
          extra: (list)
      - regexp:
          var: rest
          regexp_multi: '''\s((?:\\ |\\:|[^\s:])+):((?:\\ |[^\s])+)'''
          fail_on_non_continuous: yes
          rest: rest
          groups:
            - key_escaped
            - value_escaped
          loop:
            - vars:
                key:
                  regexp_replace:
                    var: key_escaped
                    from: \\(\\|\s|:)
                    to: $1
                value:
                  regexp_replace:
                    var: value_escaped
                    from: \\(\\|\s)
                    to: $1
            - update_map:
                var: props
                key: key
                value: value
      - regexp:
          var: rest
          regexp_multi: '''\s*\|((?:\\\||[^|])+)'''
          fail_on_non_continuous: yes
          groups:
            - extra_escaped
          loop:
            - vars:
                extra_escaped_1:
                  regexp_replace:
                    var: extra_escaped
                    from: \\r
                    to: "\r"
                extra_escaped_2:
                  regexp_replace:
                    var: extra_escaped_1
                    from: \\n
                    to: "\n"
                extra_unescaped:
                  regexp_replace:
                    var: extra_escaped_2
                    from: \\(\\|\|)
                    to: $1
            - update_list:
                var: extra
                push: extra_unescaped
      - vars:
          value:
            map:
              logLevel: log_level
              timestampString: timestamp_string
              timestampMilliseconds: timestamp_ms
              timestampMicroseconds: microseconds
              loggerKey: logger_key
              logKey: log_key
              props: props
              extra: extra
      - return:
          key: map_filter_key
          value: value

  - from: parsed-log-lines
    to: parsed-log-lines:1d
    reader_name: parsed-log-lines
    aggregate:
      key:
        - call:
            fn: *parsed_log_lines_day_date_as_key
            vars:
              source: source
            result: key
        - return: key
      map_filter:
        - vars:
            unified_logger_key:
              regexp_replace:
                var: source.loggerKey
                from: ^(master|worker)\d+
                to: $1#
            merged_log_key: ${unified_logger_key}::${source.logKey}::${logLevelLetter}
        - return: merged_log_key
      empty_accumulator:
        - return: !record
            count:
              type: int64
              value: 0
            log_keys: map<string, int64>
      initial_accumulator:
        - return:
            count: target.count
            log_keys: target.logKeys
      reduce:
        - if:
            condition: source_old is not none
            then:
              - vars:
                  key: source_old.merged_log_key
                  value: -1
              - update_record:
                  var: accumulator.count
                  value: accumulator.count + value
              - call:
                  fn: *parsed_log_lines_aggregate_increment_log_keys
                  vars:
                    accumulator: accumulator
                    count: count
                    value: value
                    key: key
        - if:
            condition: source_new is not none
            then:
              - vars:
                  key: source_new.merged_log_key
                  value: 1
              - update_record:
                  var: accumulator.count
                  value: accumulator.count + value
              - call:
                  fn: *parsed_log_lines_aggregate_increment_log_keys
                  vars:
                    accumulator: accumulator
                    count: count
                    value: value
                    key: key
      merge_accumulators:
        - update_record:
            var: accumulator.count
            value: accumulator.count + next.count
        - foreach:
            iterable: next.logKeys
            as_var: item
            body:
              - vars:
                  key: item.key
                  value: item.value
              - call:
                  fn: *parsed_log_lines_aggregate_increment_log_keys
                  vars:
                    accumulator: accumulator
                    count: count
                    value: value
                    key: key
      apply:
        - return: accumulator

  - from: parsed-log-lines
    intermediate:
      collection:
        name: updateMs:1d:intermediate
        format: json
      reader_name: parsed-log-lines
    to:
      collection: updateMs:1d:p
      reader_name: updateMs:1d:intermediate
    percentiles:
      percentiles: [0, 50, 75, 90, 95, 100]
      target_key:
        source:
          - call:
              fn: *parsed_log_lines_day_date_as_key
              vars:
                source: source
              result: key
          - return: key
        intermediate:
          - call:
              fn: *take_str_before_space
              vars:
                str: intermediate_key
              result: key
          - return: key
      intermediate:
        - vars:
            is_stats: source.logLevel == 'S'
            is_handle_full: source.logKey == 'handleFull'
            is_from_middleware:
              regexp_test:
                var: source.loggerKey
                regexp: ^worker\d*:middlewares$
        - if:
            condition: is_stats && is_handle_full && is_from_middleware
            then: noop
            else: return
        - vars:
            update_type: source.props.updateType.or_default('???')
            ms:
              parse_float: source.props.ms
        - vars:
            ms_fixed:
              positive_float_to_fixed_length_string:
                integer_digits: 9
                fractional_digits: 1
                overflow_as_max: yes
        - call:
            fn: *parsed_log_lines_day_date_as_key
            vars:
              source: source
            result: key
        - return:
            key: ${key} ${ms_fixed} ${source_key}
            value:
              updateType: update_type
              ms: ms
      empty_accumulator:
        - return: !record
            sum_ms:
              type: int64
              value: 0
            ms_by_type: map<string, int64>
      initial_accumulator:
        - return:
            sum_ms: target.sumMs
            ms_by_type: target.msByType
      reduce:
        - if:
            condition: intermediate_old is not none
            then:
              - update_record:
                  var: accumulator.sum_ms
                  value: accumulator.sum_ms - intermediate_old.sum_ms
              - vars:
                  key: intermediate_old.updateType
                  value: -1
              - call:
                  fn: *update_ms_percentiles_increment_ms_by_type
                  vars:
                    accumulator: accumulator
                    key: key
                    count: count
                    value: value
        - if:
            condition: intermediate_new is not none
            then:
              - update_record:
                  var: accumulator.sum_ms
                  value: accumulator.sum_ms + intermediate_old.sum_ms
              - vars:
                  key: intermediate_old.updateType
                  value: 1
              - call:
                  fn: *update_ms_percentiles_increment_ms_by_type
                  vars:
                    accumulator: accumulator
                    key: key
                    count: count
                    value: value
      percentiles_data:
        - return: target.percentilesData
      apply:
        - return:
            sumMs: accumulator.sum_ms
            msByType: accumulator.ms_by_type
            percentilesData: percentiles_data

  - from: parsed-log-lines
    intermediate:
      collection:
        name: uniqueChats:1d:intermediate
        format: empty
      reader_name: parsed-log-lines
    to:
      collection: uniqueChats:1d
      reader_name: uniqueChats:1d:intermediate
    unique_count:
      target_key:
        source:
          - call:
              fn: *parsed_log_lines_day_date_as_key
              vars:
                source: source
              result: key
          - return: key
        intermediate:
          - call:
              fn: *take_str_before_space
              vars:
                str: intermediate_key
              result: key
          - return: key
      intermediate:
        - vars:
            is_stats: source.logLevel == 'S'
            is_chat: source.logKey == 'chat'
            is_unique_chats:
              regexp_test:
                var: source.loggerKey
                regexp: ^[^:]+:uniqueChats$
            id: source.props.id
        - if:
            condition: is_stats && is_chat && is_unique_chats && id
            then: noop
            else: return
        - call:
            fn: *parsed_log_lines_day_date_as_key
            vars:
              source: source
            result: key
        - return:
            key: ${key} ${id}
      empty_target:
        - return:
            count: 0
      apply:
        - return:
            count: target.count + count_diff

tests:
  transforms.parse_lines.map_filter:
    - name: with props and no extras
      vars:
        map_filter_key: 'S 2023-02-20T21:42:48.822Z.000 worker258688:middlewares handleFull updateType:edited_message ms:27'
        map_filter_new_value: ''
      return:
        key: 'S 2023-02-20T21:42:48.822Z.000 worker258688:middlewares handleFull updateType:edited_message ms:27'
        value:
          logLevel: S
          timestampString: 2023-02-20T21:42:48.822Z.000
          timestampMilliseconds: 1676929368822
          timestampMicroseconds: 0
          loggerKey: worker258688:middlewares
          logKey: handleFull
          props:
            updateType: edited_message
            ms: '''27'''
          extra: []

    - name: with props and one extra
      vars:
        map_filter_key: 'S 2023-02-20T21:42:48.822Z.000 worker258688:middlewares handleFull updateType:edited_message ms:27 |some extra 1'
        map_filter_new_value: ''
      return:
        key: 'S 2023-02-20T21:42:48.822Z.000 worker258688:middlewares handleFull updateType:edited_message ms:27 |some extra 1'
        value:
          logLevel: S
          timestampString: 2023-02-20T21:42:48.822Z.000
          timestampMilliseconds: 1676929368822
          timestampMicroseconds: 0
          loggerKey: worker258688:middlewares
          logKey: handleFull
          props:
            updateType: edited_message
            ms: '''27'''
          extra:
            - some extra 1

    - name: with props and two extras
      vars:
        map_filter_key: 'S 2023-02-20T21:42:48.822Z.000 worker258688:middlewares handleFull updateType:edited_message ms:27 |some extra 2|another extra 2'
        map_filter_new_value: ''
      return:
        key: 'S 2023-02-20T21:42:48.822Z.000 worker258688:middlewares handleFull updateType:edited_message ms:27 |some extra 2|another extra 2'
        value:
          logLevel: S
          timestampString: 2023-02-20T21:42:48.822Z.000
          timestampMilliseconds: 1676929368822
          timestampMicroseconds: 0
          loggerKey: worker258688:middlewares
          logKey: handleFull
          props:
            updateType: edited_message
            ms: '''27'''
          extra:
            - some extra 2
            - another extra 2

    - name: with no props and no extras
      vars:
        map_filter_key: 'S 2023-02-20T21:42:48.822Z.000 worker258688:middlewares handleFull'
        map_filter_new_value: ''
      return:
        key: 'S 2023-02-20T21:42:48.822Z.000 worker258688:middlewares handleFull'
        value:
          logLevel: S
          timestampString: 2023-02-20T21:42:48.822Z.000
          timestampMilliseconds: 1676929368822
          timestampMicroseconds: 0
          loggerKey: worker258688:middlewares
          logKey: handleFull
          props: {}
          extra: []

    - name: with no props and two extras
      vars:
        map_filter_key: 'S 2023-02-20T21:42:48.822Z.000 worker258688:middlewares handleFull |some extra|another extra'
        map_filter_new_value: ''
      return:
        key: 'S 2023-02-20T21:42:48.822Z.000 worker258688:middlewares handleFull |some extra|another extra'
        value:
          logLevel: S
          timestampString: 2023-02-20T21:42:48.822Z.000
          timestampMilliseconds: 1676929368822
          timestampMicroseconds: 0
          loggerKey: worker258688:middlewares
          logKey: handleFull
          props: {}
          extra:
            - some extra
            - another extra
